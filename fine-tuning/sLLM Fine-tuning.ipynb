{"cells":[{"cell_type":"markdown","metadata":{"id":"hh4H0LAsts7q"},"source":["# sLLM Fine-tuning\n","- (https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eZb4TSQAolQV"},"source":["### Installation"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"p65zsX57T8f2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733029911416,"user_tz":-540,"elapsed":19482,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}},"outputId":"ddeeeb0b-1293-49b6-eb89-2fc25b9168b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install transformers trl peft accelerate datasets wandb bitsandbytes --upgrade -qqq"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3865,"status":"ok","timestamp":1733029962082,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"},"user_tz":-540},"id":"iXRKOZ4CiyOG","outputId":"231418e9-0f88-4fea-93fe-b948eeea3d6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (0.6.4.post1)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.66.6)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n","Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.46.3)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.3)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (4.25.5)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.11.2)\n","Requirement already satisfied: openai>=1.45.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.54.4)\n","Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm) (0.32.1)\n","Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.9.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (10.4.0)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.0)\n","Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (7.0.0)\n","Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.7.0)\n","Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.9)\n","Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.46)\n","Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n","Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.16.1)\n","Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.1.1.post4)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n","Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm) (0.18.6)\n","Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.5.0)\n","Requirement already satisfied: mistral-common>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.5.0->vllm) (1.5.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n","Requirement already satisfied: compressed-tensors==0.8.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n","Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.39.0)\n","Requirement already satisfied: nvidia-ml-py>=12.560.30 in /usr/local/lib/python3.10/dist-packages (from vllm) (12.560.30)\n","Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.5.1+cu121)\n","Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.1+cu121)\n","Requirement already satisfied: xformers==0.0.28.post3 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.28.post3)\n","Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.115.5)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (2024.9.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n","Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.41.3)\n","Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (0.3.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (4.23.0)\n","Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.5.0->vllm) (4.10.0.84)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (0.7.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (1.3.1)\n","Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.2.2)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n","Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.35.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n","Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (24.6.1)\n","Requirement already satisfied: pyairports in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.1.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (2.23.4)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.1.0)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2024.8.30)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.9.11)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.26.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.2->vllm) (0.4.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (24.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.21.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n","Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.6.4)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.21.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.0)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (14.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.45.0->vllm) (1.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.45.0->vllm) (1.0.7)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (2024.10.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (0.21.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.70.16)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->vllm) (3.0.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm) (1.16.0)\n"]}],"source":["!pip install vllm triton"]},{"cell_type":"markdown","metadata":{"id":"X_dTVCFlojZm"},"source":["### Mount + libraries\n","\n","- 세션 초기화 할때 마다 여기 셀들을 실행해주세요."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29754,"status":"ok","timestamp":1733029993344,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"},"user_tz":-540},"id":"CGCus84fgirY","outputId":"5287b1cf-26fa-4b22-c472-acb02eee3260"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ZRWgHZJagrSL","executionInfo":{"status":"ok","timestamp":1733029993344,"user_tz":-540,"elapsed":2,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}}},"outputs":[],"source":["path = '/content/drive/MyDrive/hackertone/'"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"u5ozuQfX1Isp","executionInfo":{"status":"ok","timestamp":1733030013197,"user_tz":-540,"elapsed":19855,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}}},"outputs":[],"source":["import torch\n","from datasets import Dataset, load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n","from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n","from trl import SFTTrainer\n","import pandas as pd\n","import numpy as np\n","import json\n","import re\n","from vllm import LLM, SamplingParams\n","import triton"]},{"cell_type":"markdown","metadata":{"id":"p65g-9UCfboo"},"source":["## Dataset 전처리"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Ks2B1cWb1OV9","executionInfo":{"status":"ok","timestamp":1733030013198,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}}},"outputs":[],"source":["def prompts(example):\n","    prompt_list = []\n","    for i in range(len(example['instruction'])):\n","        prompt_list.append(\n","f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>{example['instruction'][i]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>{example['output'][i]}<|eot_id|>\"\"\"\n","        )\n","    return prompt_list"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-lQhxSXv2iIB","executionInfo":{"status":"ok","timestamp":1733030013703,"user_tz":-540,"elapsed":512,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}}},"outputs":[],"source":["with open(path + \"craw.json\", \"r\", encoding=\"utf-8\") as f:\n","    data = json.load(f)\n","\n","# 태그 파싱\n","pattern = r'<STYLE (style=\"([^\"]+)\")?(primary=\"([^\"]+)\")?(tone=\"([^\"]+)\")?>([^<]+)</STYLE>'\n","\n","processed_data = []\n","result = {'instruction': [], 'output': []}\n","for data in data:\n","    match = re.match(pattern, data)\n","    if match:\n","        if match.group(2):\n","            result[\"instruction\"].append(f\"{match.group(2)} 스타일의 문장을 만들어줘.\")\n","        if match.group(4):\n","            result[\"instruction\"].append(f\"{match.group(4)} 어체의 문장을 만들어줘.\")\n","        if match.group(6):\n","            result[\"instruction\"].append(f\"{match.group(6)} 어체의 문장을 만들어줘.\")\n","        result[\"output\"].append(f\"{match.group(7)}\")\n","\n","processed_data = result\n","df = pd.DataFrame(processed_data)\n","from datasets import Dataset\n","dataset = Dataset.from_pandas(df)"]},{"cell_type":"code","source":["len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8gJXZeJ1Y86","executionInfo":{"status":"ok","timestamp":1733030120300,"user_tz":-540,"elapsed":890,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}},"outputId":"25d01687-7030-4e62-d56b-75fad994684d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6081"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from datasets import Dataset\n","\n","def prompts_json(json_file_path):\n","  with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n","      data = json.load(f)\n","\n","  # 태그 파싱\n","  pattern = r'<STYLE (style=\"([^\"]+)\")?(primary=\"([^\"]+)\")?(tone=\"([^\"]+)\")?>([^<]+)</STYLE>'\n","\n","  result = {'instruction': []}\n","  for data in data:\n","      match = re.match(pattern, data)\n","      if match:\n","          result[\"instruction\"].append(f\"{match.group(7)}\")\n","  return result"],"metadata":{"id":"CjMorjbN_lSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompts = prompts_json(path + \"craw.json\")"],"metadata":{"id":"QT6tsIM7An8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["instruction = '안녕, 성찰에 대해 글써줘.'"],"metadata":{"id":"Hfv4IBQ-C4Fy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 추론 수행\n","def generate_responses(instruction_msg, model, tokenizer):\n","  instruction = f'{instruction_msg}'\n","\n","  messages = [\n","      {\n","        \"role\": \"system\",\n","        \"content\": '''당신은 훌륭한 글 작성 도우미입니다.\n","        사용자의 스타일(userStyle2)에 맞춰서 입력된 글을 다시 작성해주세요.\n","        You are great writing helper.\n","        Fit on user's wrting style(userStyle2) and write articles according to it.\n","        Write in Korean'''\n","      },\n","      {\n","        \"role\": \"user\",\n","        \"content\": instruction\n","      },\n","  ]\n","\n","  prompt_message = tokenizer.apply_chat_template(\n","          messages,\n","          tokenize=False,\n","          add_generation_prompt=True,\n","  )\n","\n","  # Tokenize the prompt_message and convert to a tensor\n","  input_ids = tokenizer(prompt_message, return_tensors=\"pt\").input_ids.to(model.device)\n","\n","  eos_token_id = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n","  outputs = model.generate(\n","                input_ids,\n","                max_length=300,\n","                num_return_sequences=1,\n","                do_sample=True,\n","                top_k=50,\n","                top_p=0.95,\n","                temperature=0.7,\n","            )\n","  result = []\n","  generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","  result.append(generated_text)\n","  return result\n","\n","# 추론 결과 생성 및 출력\n","response = generate_responses(prompts['instruction'][0], model, tokenizer)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjaKhyoRBVpx","executionInfo":{"status":"ok","timestamp":1733021005053,"user_tz":-540,"elapsed":2010,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}},"outputId":"023e82ad-bb4a-4873-c240-9a0e4ceb3510"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"system\\n당신은 훌륭한 글 작성 도우미입니다.\\n        사용자의 스타일(userStyle2)에 맞춰서 입력된 글을 다시 작성해주세요.\\n        You are great writing helper.\\n        Fit on user's wrting style(userStyle2) and write articles according to it.\\n        Write in Korean\\nuser\\n안녕하십니까 형님들 오랜만에 돌아왔습니다.  코딩테스트, 다들 어떻게 준비하고 계십니까?\\nassistant\\n계십니까 준비하세요. 코딩\"]\n"]}]},{"cell_type":"markdown","metadata":{"id":"m57YTIhKfYxN"},"source":["## Modeling\n"]},{"cell_type":"markdown","metadata":{"id":"cJqkdsZls9s7"},"source":["### 모델 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3511,"status":"ok","timestamp":1733014214119,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"},"user_tz":-540},"id":"uYLWjnVxsPbN","outputId":"532372a3-53a9-4868-d78b-91dd269cc754"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["model_id = 'HuggingFaceTB/SmolLM2-135M-Instruct'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id, **{\"low_cpu_mem_usage\": True})\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    torch_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"ST9YACAtoCJ2"},"source":["###LoRA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733014214119,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"},"user_tz":-540},"id":"91eP8oWavH-b","outputId":"296040db-85d6-4762-a228-f9c136fb9a44"},"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 2,442,240 || all params: 136,957,248 || trainable%: 1.7832\n"]}],"source":["lora_config = LoraConfig(\n","    r=8,\n","    lora_alpha = 16,\n","    lora_dropout = 0.1,\n","    target_modules=['down_proj','o_proj','k_proj','q_proj','gate_proj','up_proj','v_proj'],\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    init_lora_weights=\"gaussian\"\n",")\n","\n","model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters()\n"]},{"cell_type":"markdown","metadata":{"id":"h9iRymvn2JIm"},"source":["### Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_m3OfAp2L72"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_id)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = 'left'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67CptdEG2fiX"},"outputs":[],"source":["train_data = dataset"]},{"cell_type":"markdown","metadata":{"id":"xu19Pwbvs_tR"},"source":["### Fine-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":973,"referenced_widgets":["2d1060632c1846fdaf3209aed08f902c","4d7d8e11df4d42f38717e74241ff1aca","617d05227f5342b09e380efc2c38a221","c1ff9c5de2e84cb9a923c244e59b75ab","98201b9a5444446caa53e86b37442d4b","d17cd1e18377474fb764415d8af87786","4aee9e2ccfdb4848bb3a3fe99b8465d5","fd675da985f142e5a7990b3a3fec9246","e3dc856069b94675a77f8ba4ca6005ac","15ea2274db604cf6a6987eb5979a4cc3","7daa1967a9314c49bc8dec157593c0c2"]},"id":"o2WbElsfPa0P","executionInfo":{"status":"ok","timestamp":1733014973456,"user_tz":-540,"elapsed":750647,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}},"outputId":"98912e9d-15e3-46a8-916b-e87855a6e943"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '0.13.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6081 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d1060632c1846fdaf3209aed08f902c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n","  warnings.warn(\n","max_steps is given, it will override any value given in num_train_epochs\n","`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 12:27, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.747900</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.533500</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.358500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.191000</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.035900</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.957600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.940900</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.917400</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.905500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.885000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.905300</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.878600</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.876000</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.874800</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.881900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.862500</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.860100</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.863800</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.861600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.875700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1000, training_loss=1.0106663093566894, metrics={'train_runtime': 749.0924, 'train_samples_per_second': 10.68, 'train_steps_per_second': 1.335, 'total_flos': 1327659096775680.0, 'train_loss': 1.0106663093566894, 'epoch': 1.3149243918474687})"]},"metadata":{},"execution_count":10}],"source":["lora_trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    max_seq_length=256,\n","    tokenizer=tokenizer,\n","    args=TrainingArguments(\n","        output_dir=\"outputs\",\n","        num_train_epochs = 2,\n","        max_steps=1000,\n","        per_device_train_batch_size=4,\n","        gradient_accumulation_steps=2,\n","        optim=\"paged_adamw_8bit\",\n","        warmup_steps=1,\n","        learning_rate=1e-5,\n","        fp16=True,\n","        logging_steps=50,\n","        push_to_hub=False,\n","        report_to='none',\n","    ),\n","    peft_config=lora_config,\n","    formatting_func=prompts,\n",")\n","\n","lora_trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4632,"status":"ok","timestamp":1733015347067,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"},"user_tz":-540},"id":"e3rEKVbMTn4M","outputId":"8b04a963-7c79-4013-ba0b-1cb34bad6d64"},"outputs":[{"output_type":"stream","name":"stderr","text":["Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"]},{"output_type":"execute_result","data":{"text/plain":["('SmolLM2-135M-ERAI-ver-test/tokenizer_config.json',\n"," 'SmolLM2-135M-ERAI-ver-test/special_tokens_map.json',\n"," 'SmolLM2-135M-ERAI-ver-test/vocab.json',\n"," 'SmolLM2-135M-ERAI-ver-test/merges.txt',\n"," 'SmolLM2-135M-ERAI-ver-test/added_tokens.json',\n"," 'SmolLM2-135M-ERAI-ver-test/tokenizer.json')"]},"metadata":{},"execution_count":15}],"source":["lora_model = \"lora_model\"\n","lora_trainer.model.save_pretrained(lora_model)\n","lora_trainer.tokenizer.save_pretrained(lora_model)\n","\n","model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto')\n","model = PeftModel.from_pretrained(model, lora_model, device_map='auto')\n","\n","model = model.merge_and_unload()\n","model.save_pretrained('SmolLM2-135M-ERAI')\n","tokenizer.save_pretrained('SmolLM2-135M-ERAI')"]},{"cell_type":"markdown","source":[],"metadata":{"id":"EA1l3PVU-e11"}},{"cell_type":"markdown","metadata":{"id":"y30vHBJfsgU9"},"source":["## 추론\n","- 실행 전에 세션 초기화 해주세요.\n","- 이후 위에 Mount+Libraries 셀을 실행해주세요."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287,"referenced_widgets":["38c30bc1f2d74276b6d075a983e962e4","d698e964edca45739bee174c4b00561a","97eda34396a74f77b080b87ea4ba75d3","3e719d1f04904752ade842f1e77d981d","13dafbbc2ad6488b992f03c4cb3e085f","925b0bfb8d6348528232113cf5f1fe51","0e199da2e509438b87373385eecb0706","d64b82fcceee4a4a8b1abcdc64d19527","4163a706fa054831b7accacdba1d14fd","1776643ff5834aa990ff88a06c661b0d","1e4c7df4da3e4994a5076125f30e3fe5"]},"executionInfo":{"elapsed":43013,"status":"ok","timestamp":1733015396206,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"},"user_tz":-540},"id":"akYo1rfPWQ0k","outputId":"5efc3044-f446-4ccc-99e8-f8fd0e588139"},"outputs":[{"output_type":"stream","name":"stdout","text":["INFO 12-01 01:09:13 config.py:1861] Downcasting torch.float32 to torch.float16.\n","INFO 12-01 01:09:21 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.\n","INFO 12-01 01:09:21 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='SmolLM2-135M-ERAI-ver-test', speculative_config=None, tokenizer='SmolLM2-135M-ERAI-ver-test', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=SmolLM2-135M-ERAI-ver-test, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n","INFO 12-01 01:09:21 selector.py:135] Using Flash Attention backend.\n","INFO 12-01 01:09:22 model_runner.py:1072] Starting to load model SmolLM2-135M-ERAI-ver-test...\n"]},{"output_type":"display_data","data":{"text/plain":["Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c30bc1f2d74276b6d075a983e962e4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 12-01 01:09:22 model_runner.py:1077] Loading model weights took 0.2551 GB\n","INFO 12-01 01:09:23 worker.py:232] Memory profiling results: total_gpu_memory=22.17GiB initial_memory_usage=2.10GiB peak_torch_memory=2.28GiB memory_usage_post_profile=2.10GiB non_torch_memory=0.27GiB kv_cache_size=15.18GiB gpu_memory_utilization=0.80\n","INFO 12-01 01:09:23 gpu_executor.py:113] # GPU blocks: 44224, # CPU blocks: 11650\n","INFO 12-01 01:09:23 gpu_executor.py:117] Maximum concurrency for 8192 tokens per request: 86.38x\n","INFO 12-01 01:09:27 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n","INFO 12-01 01:09:27 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","INFO 12-01 01:09:54 model_runner.py:1518] Graph capturing finished in 27 secs, took 0.79 GiB\n"]}],"source":["base_model = 'SmolLM2-135M-ERAI'\n","llm = LLM(model=base_model,\n","          # max_model_len=55000,\n","          gpu_memory_utilization=0.8)\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = 'left'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3880,"status":"ok","timestamp":1733015469309,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"},"user_tz":-540},"id":"_UYnTPvCVABg","outputId":"b464717c-aa84-47d4-a50f-099f1646f836"},"outputs":[{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it, est. speed input: 131.90 toks/s, output: 300.81 toks/s]"]},{"output_type":"stream","name":"stdout","text":["그러나 모든 디자인 자세에 대한 개발할 수 있는 과정을 실행하는 작업을 어드마케이션이 드러나지 않습니다.\n","디자인 이러한 분야입니다. \n","웹 애플리케이션에 대해 사용자가 많은 스타일을 다시 작성해 작성해주세요. 사용자가 다시 내는 작업을 보고서 받습니다.\n","사이트 서버를 사용하여 애플리케이션이 진실마를 들었습니다. 오브려는 분야는 프론트엔드를 사용하여 인터랙션을 상들고 내는 작업을 구현해주세요.\n","스타일을 보고서 받습니다. 오브려는 분야입니다.\n","사용자가 다시 내는 작업을 보고서 받습니다. 위에서 애플리케이션을 보고서 받습니다.\n","내는 작업을 보고서 받습니다. 또 무력을 줄 수 있습니다. 방법설과 스타일을 만들 수 있습니다.\n","애플리케이션을 종료하는 상황이 단축되게 되는데, 인터랙션 인식에서 특정의 사용자가 직접 상호작용하기 위해 많은 작업을 다시 들었습니다.\n","직접 상호작용하는 분야입니다. 제자를 성공적으로 보고서 받습니다. 상호작용과 더분에서 내는 작업을 받습니다.\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["instruction = '''프론트엔드 개발에 대해서 설명해줘'''\n","\n","messages = [\n","    {\n","      \"role\": \"system\",\n","      \"content\": '''당신은 훌륭한 글 작성 도우미입니다.\n","       사용자의 스타일(userStyle2)에 맞춰서 입력된 글을 다시 작성해주세요.\n","       You are great writing helper.\n","       Fit on user's wrting style(userStyle2) and write articles according to it.\n","       Write in Korean'''\n","    },\n","    {\n","      \"role\": \"user\",\n","      \"content\": instruction\n","    },\n","]\n","\n","prompt_message = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True,\n",")\n","\n","eos_token_id = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n","\n","outputs = llm.generate(prompt_message,\n","                       SamplingParams(stop_token_ids=eos_token_id, temperature=0.8, top_p=0.95,max_tokens=1024))\n","\n","for output in outputs:\n","    propt = output.prompt\n","    generated_text = output.outputs[0].text\n","    print(generated_text)"]},{"cell_type":"markdown","metadata":{"id":"Pt7PTZHWiIcu"},"source":["## ONNX 변환"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7229,"status":"ok","timestamp":1733013879574,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"},"user_tz":-540},"id":"eLMJr188h3H2","outputId":"b29d83be-25fa-4aec-fda9-f75766711dc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.20.1\n"]}],"source":["!pip install onnx onnxruntime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OuM0P0MhWHO","colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"status":"error","timestamp":1733018246912,"user_tz":-540,"elapsed":550,"user":{"displayName":"Hyunho Jang","userId":"09093243462101264059"}},"outputId":"b2d216d4-f67c-4a8f-8179-6a3570e666ab"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'torch' has no attribute 'q4f16'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-61efd032e347>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_chat_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq4f16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# ONNX 파일로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2560\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module '{__name__}' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'q4f16'"]}],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# 모델과 토크나이저 로드\n","checkpoint = \"SmolLM2-135M-ERAI-ver-test\"\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n","\n","# 예제 입력 생성 (dummy input)\n","messages = [{\"role\": \"user\", \"content\": \"translate 'I have a hat' to French\"}]\n","input_text = tokenizer.apply_chat_template(messages, tokenize=True)\n","inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n","inputs = inputs.to(torch.int)\n","\n","# ONNX 파일로 변환\n","onnx_path = \"/content/drive/MyDrive/hackertone/smollm2_135m_erai.onnx\"\n","\n","# Export 모델\n","torch.onnx.export(\n","    model,\n","    args=(inputs,),  # 모델에 전달될 입력\n","    f=onnx_path,  # 출력될 ONNX 파일 경로\n","    export_params=True,  # 학습된 파라미터 저장\n","    opset_version=17,  # ONNX opset version (최신 버전 사용 권장)\n","    input_names=[\"input_ids\"],  # 입력 이름\n","    output_names=[\"output\"],  # 출력 이름\n","    dynamic_axes={  # 동적 크기 설정\n","        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n","        \"output\": {0: \"batch_size\", 1: \"sequence_length\"}\n","    },\n","    verbose=True\n",")\n","\n","print(f\"ONNX 모델이 '{onnx_path}'에 저장되었습니다.\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["eZb4TSQAolQV","X_dTVCFlojZm","p65g-9UCfboo","cJqkdsZls9s7","ST9YACAtoCJ2","h9iRymvn2JIm","xu19Pwbvs_tR","y30vHBJfsgU9"],"gpuType":"L4","machine_shape":"hm","provenance":[{"file_id":"1E2VDoaabiOqyIhmXIbdeTwwqeqWH7gmo","timestamp":1732988214880}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2d1060632c1846fdaf3209aed08f902c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d7d8e11df4d42f38717e74241ff1aca","IPY_MODEL_617d05227f5342b09e380efc2c38a221","IPY_MODEL_c1ff9c5de2e84cb9a923c244e59b75ab"],"layout":"IPY_MODEL_98201b9a5444446caa53e86b37442d4b"}},"4d7d8e11df4d42f38717e74241ff1aca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d17cd1e18377474fb764415d8af87786","placeholder":"​","style":"IPY_MODEL_4aee9e2ccfdb4848bb3a3fe99b8465d5","value":"Map: 100%"}},"617d05227f5342b09e380efc2c38a221":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd675da985f142e5a7990b3a3fec9246","max":6081,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3dc856069b94675a77f8ba4ca6005ac","value":6081}},"c1ff9c5de2e84cb9a923c244e59b75ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15ea2274db604cf6a6987eb5979a4cc3","placeholder":"​","style":"IPY_MODEL_7daa1967a9314c49bc8dec157593c0c2","value":" 6081/6081 [00:00&lt;00:00, 7717.51 examples/s]"}},"98201b9a5444446caa53e86b37442d4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d17cd1e18377474fb764415d8af87786":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4aee9e2ccfdb4848bb3a3fe99b8465d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd675da985f142e5a7990b3a3fec9246":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3dc856069b94675a77f8ba4ca6005ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15ea2274db604cf6a6987eb5979a4cc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7daa1967a9314c49bc8dec157593c0c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38c30bc1f2d74276b6d075a983e962e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d698e964edca45739bee174c4b00561a","IPY_MODEL_97eda34396a74f77b080b87ea4ba75d3","IPY_MODEL_3e719d1f04904752ade842f1e77d981d"],"layout":"IPY_MODEL_13dafbbc2ad6488b992f03c4cb3e085f"}},"d698e964edca45739bee174c4b00561a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_925b0bfb8d6348528232113cf5f1fe51","placeholder":"​","style":"IPY_MODEL_0e199da2e509438b87373385eecb0706","value":""}},"97eda34396a74f77b080b87ea4ba75d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d64b82fcceee4a4a8b1abcdc64d19527","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4163a706fa054831b7accacdba1d14fd","value":1}},"3e719d1f04904752ade842f1e77d981d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1776643ff5834aa990ff88a06c661b0d","placeholder":"​","style":"IPY_MODEL_1e4c7df4da3e4994a5076125f30e3fe5","value":"Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00&lt;00:00,  6.42it/s]\n"}},"13dafbbc2ad6488b992f03c4cb3e085f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"925b0bfb8d6348528232113cf5f1fe51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e199da2e509438b87373385eecb0706":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d64b82fcceee4a4a8b1abcdc64d19527":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4163a706fa054831b7accacdba1d14fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1776643ff5834aa990ff88a06c661b0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e4c7df4da3e4994a5076125f30e3fe5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}